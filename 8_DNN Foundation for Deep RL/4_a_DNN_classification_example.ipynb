{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Charl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /Data_cfar10\\cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170498071/170498071 [01:48<00:00, 1567768.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /Data_cfar10\\cifar-10-python.tar.gz to /Data_cfar10\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "rootdir = '/Data_cfar10'\n",
    "T = datasets.CIFAR10(rootdir,train=True,download=True)\n",
    "V = datasets.CIFAR10(rootdir,train=False,download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 10 \n",
    "n = 1000\n",
    "inputs = np.random.rand(n, input_dim)\n",
    "outputs = np.random.randint(0, 2, n)\n",
    "\n",
    "tensor_inputs = torch.Tensor(X)\n",
    "tensor_outputs = torch.Tensor(outputs)\n",
    "tensor_df = torch._utils.data.TensorDataset(tensor_inputs, tensor_outputs)\n",
    "dataset_loader = torch.utils.data.DataLoader(tensor_df, batch_size=16, shuffle=True, drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_layer_neurons = 200\n",
    "second_layer_neurons = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(input_dim, first_layer_neurons),\n",
    "    nn.ReLU(), # Activation Function\n",
    "    nn.Linear(first_layer_neurons, second_layer_neurons),\n",
    "    nn.Tanh(), # Activation Function\n",
    "    nn.Linear(second_layer_neurons, 1),\n",
    "    nn.Sigmoid(dim=1) # Loss Function\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = T[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=32x32>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'horse'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T.classes[y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3072"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "32*32*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "T = datasets.CIFAR10(rootdir,train=True,download=True,\n",
    "                    transform=transforms.ToTensor())\n",
    "V = datasets.CIFAR10(rootdir,train=False,download=True,\n",
    "                    transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tL = torch.utils.data.DataLoader(T,batch_size=64,shuffle=True,drop_last=True)\n",
    "vL = torch.utils.data.DataLoader(V,batch_size=64,shuffle=True,drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(3072,100),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(100,10),\n",
    "    nn.LogSoftmax(dim=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.01)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer,\n",
    "                                                      len(tL))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1827.21533203125\n",
      "1799.154052734375\n"
     ]
    }
   ],
   "source": [
    "nepochs = 2\n",
    "for e in range(nepochs):\n",
    "    eLoss = 0\n",
    "    for X,y in tL:\n",
    "        batch_size = X.shape[0]\n",
    "        y_hat = model(X.view(batch_size,-1))\n",
    "        loss = loss_fn(y_hat,y)\n",
    "        eLoss += loss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    scheduler.step()\n",
    "    print(float(eLoss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0999599358974359\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "t = 0\n",
    "with torch.no_grad():\n",
    "    for Xv,yv in vL:\n",
    "        batch_size = Xv.shape[0]\n",
    "        y_hat = model(Xv.view(batch_size,-1))\n",
    "        _,p = torch.max(y_hat,dim=1)\n",
    "        t+=yv.shape[0]\n",
    "        c+=int((p==yv).sum())\n",
    "print(c/t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "5ee6f23f9c4d80c203dea4faa6a5d0c8cffa4ab65b221251ea7227320f350d1e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
